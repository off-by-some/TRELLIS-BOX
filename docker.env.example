# =============================================================================
# Trellis 3D Docker Configuration
# =============================================================================
# Copy this file to .env and modify as needed
# Usage: cp docker.env.example .env
#
# These variables are used by docker-compose.yml and can also be used
# when building directly with docker build
# =============================================================================

# -----------------------------------------------------------------------------
# CUDA and System Configuration
# -----------------------------------------------------------------------------
# CUDA version (must match available nvidia/cuda images)
# See: https://hub.docker.com/r/nvidia/cuda/tags
CUDA_VERSION=12.4.1

# cuDNN version (9 for CUDA 12.4+, 8 for older CUDA)
CUDNN_VERSION=9

# Ubuntu version
UBUNTU_VERSION=22.04

# Python version (use major.minor format, e.g., 3.10)
PYTHON_VERSION=3.10

# -----------------------------------------------------------------------------
# Python Package Versions
# -----------------------------------------------------------------------------
# Poetry version for dependency management
POETRY_VERSION=1.8.3

# PyTorch version (should match your requirements)
TORCH_VERSION=2.4.0

# Kaolin version and source URL
KAOLIN_VERSION=0.17.0
KAOLIN_INDEX_URL=https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.4.0_cu121.html

# CUDA architectures to compile for (space-separated compute capabilities)
# 7.0,7.5 = Volta/Turing (V100, RTX 2080), 8.0,8.6 = Ampere (A100, RTX 3090)
# 8.9 = Ada Lovelace (RTX 4090), 9.0 = Hopper (H100)
TORCH_CUDA_ARCH_LIST=7.0 7.5 8.0 8.6 8.9 9.0

# -----------------------------------------------------------------------------
# Application Configuration
# -----------------------------------------------------------------------------
# Application user (non-root user inside container)
APP_USER=appuser

# User ID for the app user (match your host user ID for volume permissions)
# Run `id -u` on Linux to get your user ID
APP_UID=1000

# Port inside the container (default Streamlit port)
APP_PORT=8501

# Port on the host machine (what you access in your browser)
HOST_PORT=8501

# -----------------------------------------------------------------------------
# Streamlit Configuration
# -----------------------------------------------------------------------------
# Streamlit server address (0.0.0.0 to accept all connections)
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# Run in headless mode (no browser auto-open)
STREAMLIT_SERVER_HEADLESS=true

# -----------------------------------------------------------------------------
# GPU Configuration
# -----------------------------------------------------------------------------
# Which GPUs to use (all, or comma-separated device IDs like "0,1")
CUDA_VISIBLE_DEVICES=all

# Number of GPUs to allocate (all, or a specific number)
GPU_COUNT=all

# -----------------------------------------------------------------------------
# Cache Directory Configuration
# -----------------------------------------------------------------------------
# Cache directories inside the container
CACHE_DIR=/home/appuser/.cache
HF_CACHE_DIR=/home/appuser/.cache/huggingface
REMBG_CACHE_DIR=/home/appuser/.u2net
TRELLIS_OUTPUT_DIR=/tmp/Trellis-demo

# Docker volume names for persistent storage
CACHE_VOLUME=trellis-cache
HF_CACHE_VOLUME=huggingface-cache
REMBG_CACHE_VOLUME=rembg-cache

# Host directory for outputs (relative or absolute path)
OUTPUTS_HOST_DIR=./outputs

# -----------------------------------------------------------------------------
# Docker Image Configuration
# -----------------------------------------------------------------------------
# Docker image name
IMAGE_NAME=trellis-box

# Docker image tag
IMAGE_TAG=latest

# -----------------------------------------------------------------------------
# Example Configurations for Different Scenarios
# -----------------------------------------------------------------------------

# Example 1: Use a different CUDA version (check Docker Hub for available versions)
# CUDA_VERSION=12.6.0
# CUDNN_VERSION=9

# Example 2: Change the application port
# APP_PORT=8080
# HOST_PORT=8080

# Example 3: Custom Streamlit configuration
# STREAMLIT_SERVER_ADDRESS=127.0.0.1  # Only localhost (not recommended for Docker)
# STREAMLIT_SERVER_HEADLESS=false     # Open browser automatically

# Example 4: Match host user ID (useful for file permissions)
# APP_UID=1001  # Replace with output of: id -u

# Example 5: Use only specific GPUs
# CUDA_VISIBLE_DEVICES=0,1
# GPU_COUNT=2

# Example 6: Use Python 3.11 (ensure compatibility with dependencies first)
# PYTHON_VERSION=3.11

# Example 7: Compile only for your specific GPU (faster build)
# For RTX 3090 only: TORCH_CUDA_ARCH_LIST=8.6
# For RTX 4090 only: TORCH_CUDA_ARCH_LIST=8.9
# For multiple: TORCH_CUDA_ARCH_LIST=8.6 8.9

# Example 8: Use custom cache directories
# CACHE_DIR=/data/.cache
# HF_CACHE_DIR=/data/.cache/huggingface
# REMBG_CACHE_DIR=/data/.u2net

# Example 9: Use custom volume names (useful for multiple instances)
# CACHE_VOLUME=trellis-dev-cache
# HF_CACHE_VOLUME=huggingface-dev-cache
# REMBG_CACHE_VOLUME=rembg-dev-cache

# Example 10: Store outputs in a different directory
# OUTPUTS_HOST_DIR=/path/to/my/outputs

